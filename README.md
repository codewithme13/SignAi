<div align="center">

# ğŸ¤Ÿ SignAI

### AI-Powered Sign Language Video Calling Platform

*Breaking communication barriers between deaf and hearing individuals through real-time AI translation*

[![Flutter](https://img.shields.io/badge/Flutter-3.2.0+-02569B?style=for-the-badge&logo=flutter&logoColor=white)](https://flutter.dev)
[![Node.js](https://img.shields.io/badge/Node.js-18.0+-339933?style=for-the-badge&logo=node.js&logoColor=white)](https://nodejs.org)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14+-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)](https://www.postgresql.org)
[![WebRTC](https://img.shields.io/badge/WebRTC-P2P-333333?style=for-the-badge&logo=webrtc&logoColor=white)](https://webrtc.org)

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Architecture](#-architecture) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [API](#-api-reference) â€¢ [Contributing](#-contributing)

---

<!-- BURAYA: Uygulama ekran gÃ¶rÃ¼ntÃ¼sÃ¼ veya demo GIF'i ekle -->
<!-- Ã–rnek: Ana ekran + Arama ekranÄ± yan yana -->

</div>

---

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Demo](#-demo)
- [How It Works](#-how-it-works)
- [System Architecture](#-architecture)
- [Technology Stack](#-technology-stack)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [API Reference](#-api-reference)
- [Security](#-security)
- [Contributing](#-contributing)
- [License](#-license)
- [Contact](#-contact)

---

## ğŸŒŸ Overview

**SignAI** is an innovative AI-powered video calling application designed to eliminate communication barriers between deaf and hearing individuals. Using advanced machine learning and WebRTC technology, SignAI provides real-time sign language detection and speech-to-text conversion, enabling seamless bidirectional communication.

### The Problem

Over 466 million people worldwide are deaf or hard of hearing. Traditional video calling platforms don't provide real-time translation between sign language and spoken language, creating significant communication barriers.

### The Solution

SignAI uses Google ML Kit's pose detection to recognize Turkish Sign Language (TÄ°D) gestures in real-time while simultaneously converting speech to text, displaying both as live subtitles during video calls.

<!-- BURAYA: Sistem akÄ±ÅŸ diyagramÄ± veya kullanÄ±m senaryosu gÃ¶rseli -->

---

## âœ¨ Features

### ğŸ¥ **P2P Encrypted Video Calling**
- End-to-end encrypted video/audio using WebRTC DTLS-SRTP
- Low-latency peer-to-peer connection
- HD video quality (640Ã—480 @ 24fps)
- STUN/TURN server support for NAT traversal

### ğŸ¤– **AI-Powered Sign Language Detection**
- Real-time recognition of 10 Turkish Sign Language gestures
- Google ML Kit Pose Detection integration
- Gesture validation with consistency buffer (5/10 frames)
- Smart cooldown mechanism to prevent spam

**Recognized Gestures:**
| Turkish | English | Detection Method |
|---------|---------|------------------|
| Merhaba | Hello | Right hand raised above head |
| TeÅŸekkÃ¼rler | Thank you | Hand moves from chin downward |
| Evet | Yes | Fist at head level, downward motion |
| HayÄ±r | No | Index finger swaying left-right |
| YardÄ±m | Help | Both arms raised above head |
| Yemek | Food | Right hand at mouth level |
| Su | Water | C-shaped hand at chin level |
| Dur | Stop | Open palm at chest level |
| HoÅŸÃ§akal | Goodbye | Hand waving at face level |
| Ben | Me | Index finger pointing to chest |

### ğŸ¤ **Speech-to-Text Conversion**
- Real-time Turkish speech recognition
- Automatic restart mechanism (30-second windows)
- Partial and final transcription results
- Low-latency subtitle display

### ğŸ’¬ **Dual Subtitle System**
- ğŸ¤Ÿ **Purple subtitles** for sign language (AI detected)
- ğŸ¤ **Cyan subtitles** for speech (STT converted)
- Bidirectional subtitle streaming
- 3-second display duration with fade effects

### ğŸ‘¤ **User Management**
- JWT-based authentication (7-day expiry)
- Profile photo upload/delete
- Online status indicator
- Call history tracking

### ğŸ¨ **Modern UI/UX**
- Dark/Light theme support
- Smooth animations and transitions
- Responsive design
- Picture-in-picture video layout
- Draggable local video preview

<!-- BURAYA: UI ekran gÃ¶rÃ¼ntÃ¼leri (Login, Home, Call screens) -->

---

## ğŸ¬ Demo

<!-- BURAYA: Demo videosu veya GIF animasyonu ekle -->
<!-- Ã–rnek kullanÄ±m senaryosu: -->
<!-- 1. KullanÄ±cÄ± A "Merhaba" iÅŸareti yapÄ±yor â†’ KullanÄ±cÄ± B ekranÄ±nda "Merhaba" altyazÄ±sÄ± gÃ¶rÃ¼nÃ¼yor -->
<!-- 2. KullanÄ±cÄ± B "Selam" diyor â†’ KullanÄ±cÄ± A ekranÄ±nda "Selam" altyazÄ±sÄ± gÃ¶rÃ¼nÃ¼yor -->

---

## ğŸ”„ How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User A      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Signaling       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  User B      â”‚
â”‚  (Flutter)   â”‚   WS    â”‚  Server          â”‚   WS    â”‚  (Flutter)   â”‚
â”‚              â”‚         â”‚  (Node.js)       â”‚         â”‚              â”‚
â”‚  ğŸ¤Ÿ Signs    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  ğŸ¤ Speaks   â”‚
â”‚  "Hello"     â”‚              â–²                        â”‚  "Hi"        â”‚
â”‚              â”‚              â”‚ SDP/ICE Signaling      â”‚              â”‚
â”‚  AI: "Hello" â”‚              â”‚                        â”‚  STT: "Hi"   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€ P2P (DTLS-SRTP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Subtitle:   â”‚      Direct Video/Audio Stream        â”‚  Subtitle:   â”‚
â”‚  "Hi" ğŸ¤     â”‚      (NOT through server)             â”‚  "Hello" ğŸ¤Ÿ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Call Flow Sequence

1. **User A** initiates call â†’ Creates WebRTC offer â†’ Sends via signaling server
2. **Server** forwards incoming call notification to User B
3. **User B** accepts â†’ Creates WebRTC answer â†’ Sends back via signaling server
4. **ICE Candidates** exchanged bidirectionally for NAT traversal
5. **P2P Connection** established with DTLS-SRTP encryption
6. **AI Pipeline** starts:
   - Every 200ms, capture frame from WebRTC camera
   - Process through ML Kit Pose Detection
   - Detect gestures and form sentences
   - Send subtitles to remote peer via WebSocket
7. **Speech Recognition** runs continuously:
   - Listen to microphone
   - Convert speech to text in real-time
   - Send subtitles to remote peer
8. **Call End** â†’ Close WebRTC connection, stop AI processing

<!-- BURAYA: Sequence diagram gÃ¶rseli -->

---

## ğŸ— Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PRESENTATION LAYER                   â”‚
â”‚  Screens (6)  â”‚  Widgets (4)  â”‚  Theme/Constants    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 STATE MANAGEMENT                     â”‚
â”‚  AuthProvider  â”‚  CallProvider  â”‚  ThemeProvider    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 SERVICE LAYER                        â”‚
â”‚  WebRTC â”‚ Signaling â”‚ SignLanguage â”‚ STT â”‚ Perms   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 NETWORK LAYER                        â”‚
â”‚  Socket.IO (WS) â”‚ HTTP/REST â”‚ WebRTC (P2P)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 BACKEND                              â”‚
â”‚  Express â”‚ Socket.IO â”‚ PostgreSQL â”‚ JWT/bcrypt     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Schema

```sql
-- Users Table
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    last_seen TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    is_online BOOLEAN DEFAULT false
);

-- Call History Table
CREATE TABLE call_history (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    caller_id UUID REFERENCES users(id),
    callee_id UUID REFERENCES users(id),
    started_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    ended_at TIMESTAMP WITH TIME ZONE,
    duration_seconds INTEGER,
    status VARCHAR(20) DEFAULT 'initiated',
    end_reason VARCHAR(50)
);
```

<!-- BURAYA: Architecture diagram veya component interaction gÃ¶rseli -->

---

## ğŸ›  Technology Stack

### Mobile Application (Flutter)

| Technology | Version | Purpose |
|------------|---------|---------|
| **Flutter** | 3.2.0+ | Cross-platform mobile framework |
| **flutter_webrtc** | 0.12.4 | P2P video/audio calling |
| **google_mlkit_pose_detection** | 0.12.0 | Sign language gesture detection |
| **speech_to_text** | 7.0.0 | Speech-to-text conversion |
| **socket_io_client** | 2.0.3+1 | WebSocket signaling |
| **provider** | 6.1.1 | State management |
| **shared_preferences** | 2.2.2 | Local persistent storage |

### Backend (Node.js)

| Technology | Version | Purpose |
|------------|---------|---------|
| **Express** | 4.18.2 | HTTP server & REST API |
| **Socket.IO** | 4.7.4 | Real-time WebSocket communication |
| **PostgreSQL** | 14+ | Relational database |
| **jsonwebtoken** | 9.0.2 | JWT authentication |
| **bcrypt** | 6.0.0 | Password hashing |
| **helmet** | 7.1.0 | Security headers |
| **express-rate-limit** | 7.1.5 | API rate limiting |

### Infrastructure

- **WebRTC Protocols:** DTLS-SRTP, ICE, SDP
- **STUN Servers:** Google STUN (`stun.l.google.com:19302`)
- **TURN Servers:** OpenRelay (`openrelay.metered.ca`)
- **Target Platform:** Android (min SDK 21)

---

## ğŸ“ Project Structure

```
signai/
â”œâ”€â”€ signai_app/                      # Flutter Mobile Application
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ main.dart                # App entry point
â”‚   â”‚   â”œâ”€â”€ screens/                 # 6 UI screens
â”‚   â”‚   â”‚   â”œâ”€â”€ splash_screen.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ login_screen.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ home_screen.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ call_screen.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_screen.dart
â”‚   â”‚   â”‚   â””â”€â”€ privacy_security_screen.dart
â”‚   â”‚   â”œâ”€â”€ providers/               # State management
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_provider.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ call_provider.dart
â”‚   â”‚   â”‚   â””â”€â”€ theme_provider.dart
â”‚   â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ webrtc_service.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ signaling_service.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ sign_language_service.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ speech_to_text_service.dart
â”‚   â”‚   â”‚   â””â”€â”€ permission_service.dart
â”‚   â”‚   â”œâ”€â”€ widgets/                 # Reusable components
â”‚   â”‚   â”‚   â”œâ”€â”€ call_controls.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ call_timer.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ incoming_call_dialog.dart
â”‚   â”‚   â”‚   â””â”€â”€ subtitle_overlay.dart
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ constants.dart
â”‚   â”‚       â””â”€â”€ theme.dart
â”‚   â”œâ”€â”€ android/                     # Android native code
â”‚   â”œâ”€â”€ ios/                         # iOS native code
â”‚   â””â”€â”€ pubspec.yaml
â”‚
â””â”€â”€ signaling_server/                # Node.js Signaling Server
    â”œâ”€â”€ server.js                    # Main server (Express + Socket.IO)
    â”œâ”€â”€ auth.js                      # JWT + bcrypt authentication
    â”œâ”€â”€ db.js                        # PostgreSQL database layer
    â”œâ”€â”€ validation.js                # Input validation
    â”œâ”€â”€ package.json
    â””â”€â”€ .env.example
```

**Code Statistics:**
- Flutter App: ~4,424 lines of Dart
- Backend: ~1,247 lines of JavaScript
- **Total:** ~5,671 lines of code

---

## ğŸš€ Installation

### Prerequisites

- Flutter SDK â‰¥ 3.2.0
- Node.js â‰¥ 18.0.0
- PostgreSQL â‰¥ 14
- Android Studio + Android Emulator or physical device

### 1. Clone Repository

```bash
git clone https://github.com/codewithme13/SignAi.git
cd SignAi
```

### 2. Database Setup

```bash
# Create PostgreSQL database
createdb signai_db

# Tables will be auto-created on first server run
```

### 3. Backend Setup

```bash
cd signaling_server

# Install dependencies
npm install

# Configure environment variables
cp .env.example .env
nano .env
```

Edit `.env` file:
```env
DATABASE_URL=postgresql://username:password@localhost:5432/signai_db
JWT_SECRET=your-super-secret-key-change-this
JWT_EXPIRY=7d
PORT=3001
CORS_ORIGIN=*
```

```bash
# Start server
npm start
# Server running at http://localhost:3001
```

### 4. Mobile App Setup

```bash
cd ../signai_app

# Install Flutter dependencies
flutter pub get

# Update server URL in lib/utils/constants.dart
# Change: static const String serverUrl = 'http://YOUR_SERVER_IP:3001';

# For emulator, use ADB reverse:
adb reverse tcp:3001 tcp:3001

# Run on connected device
flutter run

# Or build APK
flutter build apk --release
```

---

## âš™ï¸ Configuration

### Server Configuration

Edit `signaling_server/.env`:

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | PostgreSQL connection string | Required |
| `JWT_SECRET` | Secret key for JWT signing | Required |
| `JWT_EXPIRY` | Token expiration time | `7d` |
| `PORT` | Server port | `3001` |
| `CORS_ORIGIN` | Allowed CORS origins | `*` |

### App Configuration

Edit `signai_app/lib/utils/constants.dart`:

```dart
class AppConstants {
  static const String serverUrl = 'http://YOUR_SERVER_IP:3001';
  static const int connectionTimeout = 30;
  static const int maxReconnectAttempts = 5;
  static const int subtitleDisplayDuration = 3;
}
```

### Android Permissions

Required permissions in `android/app/src/main/AndroidManifest.xml`:

```xml
<uses-permission android:name="android.permission.INTERNET"/>
<uses-permission android:name="android.permission.CAMERA"/>
<uses-permission android:name="android.permission.RECORD_AUDIO"/>
<uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS"/>
<uses-permission android:name="android.permission.VIBRATE"/>
<uses-permission android:name="android.permission.WAKE_LOCK"/>
```

---

## ğŸ’¡ Usage

### For End Users

1. **Register/Login**
   - Launch app â†’ Enter username and password
   - Tap "KayÄ±t Ol" (Register) or "GiriÅŸ Yap" (Login)

2. **Start a Call**
   - On Home screen, enter target User ID or select from online users
   - Tap "GÃ¶rÃ¼ntÃ¼lÃ¼ Arama BaÅŸlat" (Start Video Call)
   - Grant camera/microphone permissions if prompted

3. **During Call**
   - ğŸ¤Ÿ Make sign language gestures â†’ AI detects and shows purple subtitles
   - ğŸ¤ Speak â†’ Speech-to-text converts and shows cyan subtitles
   - Toggle camera/mic using bottom controls
   - Tap red phone icon to end call

4. **View Profile**
   - Tap profile card â†’ Upload photo, change theme, view settings

### For Developers

#### Testing with Android Emulator

```bash
# Start emulator
~/Library/Android/sdk/emulator/emulator -avd Medium_Phone_API_36 &

# Set up port forwarding
adb reverse tcp:3001 tcp:3001

# Install and run
flutter run
```

#### Testing Sign Language Detection

The AI recognizes gestures when:
- Face is clearly visible in frame
- Hands are raised above waist level
- Gesture held for at least 5 frames (consistency buffer)
- 2-second cooldown between same gestures

<!-- BURAYA: Gesture detection demo GIF veya Ã¶rnek ekran gÃ¶rÃ¼ntÃ¼leri -->

---

## ğŸ“¡ API Reference

### REST Endpoints

#### Authentication

**POST** `/api/auth/register`
```json
Request:
{
  "username": "john_doe",
  "password": "secure123"
}

Response (201):
{
  "success": true,
  "data": {
    "userId": "550e8400-e29b-41d4-a716-446655440000",
    "username": "john_doe",
    "token": "eyJhbGciOiJIUzI1NiIs..."
  }
}
```

**POST** `/api/auth/login`
- Same request/response format as register

#### Users

**GET** `/api/users` (Auth required)
- Returns list of online users with profile photos

**GET** `/api/users/:userId` (Auth required)
- Get specific user details

#### Profile

**POST** `/api/profile/photo` (Auth required)
- Upload profile photo (multipart/form-data, max 2MB)
- Allowed formats: JPEG, PNG, GIF, WEBP

**DELETE** `/api/profile/photo` (Auth required)
- Delete profile photo

#### Call History

**GET** `/api/calls/history` (Auth required)
- Returns last 50 call records for authenticated user

### WebSocket Events

#### Client â†’ Server

| Event | Data | Description |
|-------|------|-------------|
| `register` | `{ userId }` | Register user as online |
| `call-user` | `{ targetUserId, offer, callerName }` | Initiate call |
| `answer-call` | `{ targetUserId, answer }` | Accept call |
| `reject-call` | `{ callerId }` | Reject call |
| `ice-candidate` | `{ targetUserId, candidate }` | Share ICE candidate |
| `end-call` | `{ targetUserId }` | End call |
| `subtitle` | `{ targetUserId, text, type }` | Send subtitle |

#### Server â†’ Client

| Event | Data | Description |
|-------|------|-------------|
| `registered` | `{ userId, onlineUsers }` | Registration confirmed |
| `incoming-call` | `{ callerId, callerName, callerPhoto, offer }` | Incoming call notification |
| `call-answered` | `{ answer }` | Call accepted |
| `call-rejected` | `{ reason }` | Call rejected |
| `call-ended` | `{}` | Call terminated |
| `ice-candidate` | `{ candidate }` | Remote ICE candidate |
| `subtitle` | `{ text, type }` | Remote subtitle |
| `user-online` | `{ userId, username, photoUrl }` | User came online |
| `user-offline` | `{ userId }` | User went offline |

---

## ğŸ”’ Security

### Communication Security

| Layer | Method | Details |
|-------|--------|---------|
| **Video/Audio** | DTLS-SRTP | WebRTC's built-in end-to-end encryption |
| **Signaling** | WSS/HTTPS | WebSocket Secure (TLS in production) |
| **API** | JWT Bearer | Token-based authentication |
| **Socket.IO** | JWT Auth | WebSocket connection authentication |
| **Passwords** | bcrypt (12 rounds) | One-way hashing, brute-force resistant |

### Server Security

- **Rate Limiting:** 100 req/min (REST), 50 events/min (Socket)
- **Helmet:** XSS, clickjacking, MIME sniffing protection
- **CORS:** Configurable origin restriction
- **Input Validation:** All inputs sanitized and validated
- **File Upload:** 2MB limit, MIME type verification

### Privacy

- **P2P Connection:** Video/audio data does NOT pass through server
- **Token Expiry:** 7 days (configurable)
- **Password Requirements:** Minimum 6 characters
- **No Data Logging:** Subtitle content not stored on server

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### Development Setup

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Test thoroughly (unit tests, integration tests)
5. Commit: `git commit -m 'Add amazing feature'`
6. Push: `git push origin feature/amazing-feature`
7. Open a Pull Request

### Code Style

- **Flutter:** Follow [Effective Dart](https://dart.dev/guides/language/effective-dart) guidelines
- **Node.js:** Use ESLint with provided config
- **Commits:** Use [Conventional Commits](https://www.conventionalcommits.org/)

### Areas for Contribution

- [ ] Add more sign language gestures (currently 10 â†’ expand to 50+)
- [ ] Support for additional languages (currently Turkish only)
- [ ] iOS platform support
- [ ] Group video calling (multi-party)
- [ ] AI model training improvements
- [ ] UI/UX enhancements
- [ ] Documentation translations

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“ Contact

**Project Maintainer:** codewithme13

- GitHub: [@codewithme13](https://github.com/codewithme13)
- Project Link: [https://github.com/codewithme13/SignAi](https://github.com/codewithme13/SignAi)

---

## ğŸ™ Acknowledgments

- **Google ML Kit** for pose detection capabilities
- **WebRTC** community for P2P communication standards
- **Flutter** team for excellent cross-platform framework
- **Turkish Sign Language** experts for gesture validation
- OpenRelay for free TURN server services

---

<div align="center">

### â­ Star this repo if you find it helpful!

Made with â¤ï¸ for the deaf and hard-of-hearing community

[Back to Top](#-signai)

</div>
