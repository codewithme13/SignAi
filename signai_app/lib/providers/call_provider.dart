/// ============================================
/// SignAI - Call Provider (Arama YÃ¶netimi)
/// ============================================
/// WebRTC + AI Pipeline + Signaling
///
/// KAMERA MÄ°MARÄ°SÄ° (v2 - Tek Kamera):
/// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
/// â”‚ WebRTC      â”‚â”€â”€â”€â”€â”€>â”‚ KarÅŸÄ± tarafa video â”‚  (P2P stream)
/// â”‚ getUserMediaâ”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/// â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
///        â”‚ (aynÄ± stream Ã¼zerinden pose detection)
///        â–¼
/// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
/// â”‚ ML Kit Pose Det.  â”‚â”€â”€â”€â”€â”€>â”‚ Subtitleâ”‚
/// â”‚ (frame by frame)  â”‚      â”‚ overlay â”‚
/// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
///
/// v2'de TEK kamera stream'i kullanÄ±lÄ±r.
/// Camera package kaldÄ±rÄ±ldÄ± â€” Ã§ift kamera Ã§akÄ±ÅŸmasÄ± Ã¶nlendi.
/// ============================================

import 'dart:async';
import 'dart:ui' as ui;
import 'package:flutter/foundation.dart';
import 'package:google_mlkit_pose_detection/google_mlkit_pose_detection.dart';
import '../services/webrtc_service.dart';
import '../services/signaling_service.dart';
import '../services/sign_language_service.dart';
import '../services/speech_to_text_service.dart';
import '../services/permission_service.dart';

class CallProvider with ChangeNotifier {
  final WebRTCService webrtc = WebRTCService();
  final SignalingService signaling = SignalingService();
  final SignLanguageService signLanguage = SignLanguageService();
  final SpeechToTextService speechToText = SpeechToTextService();

  // AI pipeline durumu
  bool _isAiRunning = false;

  // Online kullanÄ±cÄ±lar
  final List<Map<String, dynamic>> _onlineUsers = [];
  List<Map<String, dynamic>> get onlineUsers => List.unmodifiable(_onlineUsers);

  // Aktif arama bilgisi
  String? _currentCallUserId;
  String? _currentCallUserName;
  String? get currentCallUserId => _currentCallUserId;
  String? get currentCallUserName => _currentCallUserName;

  // AltyazÄ±lar
  String _signSubtitle = '';
  String _speechSubtitle = '';
  String get signSubtitle => _signSubtitle;
  String get speechSubtitle => _speechSubtitle;

  // Gelen arama
  IncomingCall? _incomingCall;
  IncomingCall? get incomingCall => _incomingCall;
  bool get hasIncomingCall => _incomingCall != null;

  // AI durumu
  bool get isAiRunning => _isAiRunning;

  // Hata mesajÄ±
  String? _lastError;
  String? get lastError => _lastError;

  // BaÅŸlatÄ±lma durumu
  bool _isInitialized = false;
  bool get isInitialized => _isInitialized;

  /// TÃ¼m servisleri baÅŸlat
  Future<void> initializeServices({
    String? token,
    String? userId,
    String? username,
  }) async {
    try {
      // Ã–nce izinleri kontrol et
      final permissions = await PermissionService.requestAllPermissions();
      if (permissions['camera'] != true || permissions['microphone'] != true) {
        _lastError = 'Kamera ve mikrofon izinleri gerekli';
        debugPrint('âŒ $_lastError');
        notifyListeners();
        return;
      }

      await webrtc.initialize();
      await signLanguage.initialize();

      // KonuÅŸma izni varsa STT'yi baÅŸlat, yoksa sadece uyar
      if (permissions['speech'] == true) {
        await speechToText.initialize();
      } else {
        debugPrint('âš ï¸ KonuÅŸma tanÄ±ma izni yok, STT devre dÄ±ÅŸÄ±');
      }

      await signaling.connect(
        token: token,
        userId: userId,
        username: username,
      );

      _setupCallbacks();
      _isInitialized = true;
      _lastError = null;
      debugPrint('âœ… TÃ¼m servisler baÅŸlatÄ±ldÄ±');
      notifyListeners();
    } catch (e) {
      _lastError = 'Servis baÅŸlatma hatasÄ±: $e';
      debugPrint('âŒ $_lastError');
      notifyListeners();
    }
  }

  /// Callback'leri kur
  void _setupCallbacks() {
    // --- Signaling callback'leri ---
    signaling.onIncomingCall = (call) {
      _incomingCall = call;
      notifyListeners();
    };

    signaling.onCallAnswered = (answer) async {
      try {
        await webrtc.handleAnswer(answer);
      } catch (e) {
        debugPrint('âŒ Answer iÅŸleme hatasÄ±: $e');
        _lastError = 'BaÄŸlantÄ± kurulamadÄ±';
        notifyListeners();
      }
    };

    signaling.onCallRejected = (_) {
      _currentCallUserId = null;
      _currentCallUserName = null;
      webrtc.hangUp();
      notifyListeners();
    };

    signaling.onCallEnded = (_) {
      endCall(sendSignal: false);
    };

    signaling.onIceCandidate = (candidate) async {
      await webrtc.addIceCandidate(candidate);
    };

    signaling.onTypedSubtitle = (text, type, fromUserId) {
      if (type == 'sign') {
        _signSubtitle = text;
      } else {
        _speechSubtitle = text;
      }
      notifyListeners();
    };

    // Eski callback'i de tutuyoruz (uyumluluk iÃ§in)
    signaling.onSubtitle = null;

    signaling.onUserOnline = (user) {
      if (!_onlineUsers.any((u) => u['userId'] == user['userId'])) {
        _onlineUsers.add(user);
        notifyListeners();
      }
    };

    signaling.onUserOffline = (user) {
      _onlineUsers.removeWhere((u) => u['userId'] == user['userId']);
      notifyListeners();
    };

    signaling.onOnlineUsers = (users) {
      _onlineUsers.clear();
      _onlineUsers.addAll(users);
      notifyListeners();
    };

    // Arama hatasÄ± (kullanÄ±cÄ± Ã§evrimdÄ±ÅŸÄ±, geÃ§ersiz ID vs.)
    signaling.onCallError = (message) {
      debugPrint('âš ï¸ Arama hatasÄ±: $message');
      _lastError = message;
      // Arama durumunu temizle
      _currentCallUserId = null;
      _currentCallUserName = null;
      webrtc.hangUp();
      notifyListeners();
    };

    // --- WebRTC callback'leri ---
    webrtc.onCallStateChanged = (state) {
      if (state == CallState.connected) {
        _startAiProcessing();
      } else if (state == CallState.ended) {
        _stopAiProcessing();
      }
      notifyListeners();
    };

    webrtc.onIceCandidate = (candidate) {
      if (_currentCallUserId != null) {
        signaling.sendIceCandidate(
          _currentCallUserId!,
          candidate.toMap(),
        );
      }
    };

    webrtc.onError = (errorMessage) {
      _lastError = errorMessage;
      notifyListeners();
    };

    // --- Ä°ÅŸaret dili callback'leri ---
    signLanguage.onWordConfirmed = (word) {
      debugPrint('ğŸ¤Ÿ Kelime onaylandÄ±: $word');
    };

    signLanguage.onSentenceFormed = (sentence) {
      _signSubtitle = sentence;
      if (_currentCallUserId != null) {
        signaling.sendSubtitle(_currentCallUserId!, sentence, type: 'sign');
      }
      notifyListeners();
    };

    // --- KonuÅŸma tanÄ±ma callback'leri ---
    // NOT: speech_to_text YEREL mikrofonu dinler.
    // Bu cihazdaki kullanÄ±cÄ±nÄ±n sesini yazÄ±ya Ã§evirir.
    // YazÄ±ya Ã§evrilen metin karÅŸÄ± tarafa altyazÄ± olarak gÃ¶nderilir.
    speechToText.onTextRecognized = (text, isFinal) {
      if (isFinal && text.isNotEmpty && _currentCallUserId != null) {
        signaling.sendSubtitle(_currentCallUserId!, text);
      }
      notifyListeners();
    };
  }

  // ============ AI Ä°ÅLEME ============

  Timer? _aiTimer;

  /// WebRTC local stream'den periyodik frame yakalayÄ±p ML Kit'e gÃ¶nderir.
  /// flutter_webrtc doÄŸrudan raw frame callback sunmaz, bu yÃ¼zden
  /// `MediaStreamTrack.captureFrame()` ile RGBA frame yakalar,
  /// ardÄ±ndan dosya tabanlÄ± InputImage oluÅŸturup pose detection yaparÄ±z.
  void _startAiProcessing() {
    if (_isAiRunning) return;
    _isAiRunning = true;
    debugPrint('ğŸ¤– AI iÅŸleme baÅŸlatÄ±ldÄ±');
    notifyListeners();

    // Her 200ms'de bir frame yakala ve iÅŸle
    _aiTimer = Timer.periodic(const Duration(milliseconds: 200), (_) {
      _captureAndProcessFrame();
    });
  }

  bool _isCapturing = false;

  Future<void> _captureAndProcessFrame() async {
    if (!_isAiRunning || !signLanguage.isInitialized) return;
    if (_isCapturing) return; // Ã–nceki frame hÃ¢lÃ¢ iÅŸleniyorsa atla
    _isCapturing = true;

    final localStream = webrtc.localStream;
    if (localStream == null) { _isCapturing = false; return; }

    final videoTracks = localStream.getVideoTracks();
    if (videoTracks.isEmpty) { _isCapturing = false; return; }

    try {
      // flutter_webrtc captureFrame() â†’ encoded image (PNG) ByteBuffer
      final buffer = await videoTracks.first.captureFrame();
      final pngBytes = buffer.asUint8List();

      // PNGâ€™yi bellekte decode et (disk I/Oâ€™dan kaÃ§Ä±n)
      final codec = await ui.instantiateImageCodec(pngBytes);
      final frameInfo = await codec.getNextFrame();
      final image = frameInfo.image;
      final width = image.width;
      final height = image.height;

      final byteData = await image.toByteData(
        format: ui.ImageByteFormat.rawRgba,
      );
      image.dispose();

      if (byteData == null) return;

      final rawBytes = byteData.buffer.asUint8List();

      // RGBA â†’ InputImage (ML Kit BGRA8888 formatÄ±nda bekler,
      // ancak RGBA ile de Ã§alÄ±ÅŸÄ±r â€” pose detection iÃ§in renk sÄ±rasÄ± Ã¶nemsiz)
      final inputImage = InputImage.fromBytes(
        bytes: rawBytes,
        metadata: InputImageMetadata(
          size: ui.Size(width.toDouble(), height.toDouble()),
          rotation: InputImageRotation.rotation0deg,
          format: InputImageFormat.bgra8888,
          bytesPerRow: width * 4,
        ),
      );

      // ML Kit Pose Detection ile iÅŸle
      await signLanguage.processFrame(inputImage);
    } catch (e) {
      // Frame yakalama her zaman baÅŸarÄ±lÄ± olmayabilir
      debugPrint('âš ï¸ AI frame hatasÄ±: $e');
    } finally {
      _isCapturing = false;
    }
  }

  void _stopAiProcessing() {
    if (!_isAiRunning) return;
    _aiTimer?.cancel();
    _aiTimer = null;
    _isAiRunning = false;
    debugPrint('ğŸ¤– AI iÅŸleme durduruldu');
  }

  // ============ KULLANICI Ä°ÅLEMLERÄ° ============

  void registerUser(String userId, String username) {
    signaling.register(userId, username);
  }

  /// Arama baÅŸlat
  Future<void> startCall(String targetUserId, String targetUserName,
      String myUserId, String myUsername) async {
    try {
      _currentCallUserId = targetUserId;
      _currentCallUserName = targetUserName;
      _lastError = null;

      await webrtc.openUserMedia();
      final offer = await webrtc.createOffer();

      signaling.callUser(targetUserId, offer.toMap(), {
        'userId': myUserId,
        'username': myUsername,
      });

      await speechToText.startListening();
      notifyListeners();
    } catch (e) {
      debugPrint('âŒ Arama baÅŸlatma hatasÄ±: $e');
      _lastError = 'Arama baÅŸlatÄ±lamadÄ±: $e';
      _currentCallUserId = null;
      _currentCallUserName = null;
      notifyListeners();
      rethrow;
    }
  }

  /// Gelen aramayÄ± kabul et
  Future<void> acceptCall() async {
    if (_incomingCall == null) return;

    try {
      _currentCallUserId = _incomingCall!.callerId;
      _currentCallUserName = _incomingCall!.callerName;
      _lastError = null;

      await webrtc.openUserMedia();
      final answer = await webrtc.createAnswer(_incomingCall!.offer);
      signaling.answerCall(_currentCallUserId!, answer.toMap());

      _incomingCall = null;
      await speechToText.startListening();
      notifyListeners();
    } catch (e) {
      debugPrint('âŒ Arama kabul hatasÄ±: $e');
      _lastError = 'Arama kabul edilemedi: $e';
      _currentCallUserId = null;
      _currentCallUserName = null;
      _incomingCall = null;
      notifyListeners();
      rethrow;
    }
  }

  /// Gelen aramayÄ± reddet
  void rejectCall() {
    if (_incomingCall == null) return;
    signaling.rejectCall(_incomingCall!.callerId);
    _incomingCall = null;
    notifyListeners();
  }

  /// AramayÄ± sonlandÄ±r
  /// [sendSignal] false ise karÅŸÄ± tarafa sinyal gÃ¶ndermez (zaten karÅŸÄ± taraftan geldi)
  Future<void> endCall({bool sendSignal = true}) async {
    try {
      if (sendSignal && _currentCallUserId != null) {
        signaling.endCall(_currentCallUserId!);
      }

      _stopAiProcessing();
      await webrtc.hangUp();
      await speechToText.stopListening();
      signLanguage.clearSentence();

      _currentCallUserId = null;
      _currentCallUserName = null;
      _signSubtitle = '';
      _speechSubtitle = '';
      _incomingCall = null;

      notifyListeners();
    } catch (e) {
      debugPrint('âš ï¸ Arama sonlandÄ±rma hatasÄ±: $e');
    }
  }

  void toggleMic() {
    webrtc.toggleMic();
    notifyListeners();
  }

  void toggleCamera() {
    webrtc.toggleCamera();
    notifyListeners();
  }

  Future<void> switchCamera() async {
    await webrtc.switchCamera();
    notifyListeners();
  }

  void clearError() {
    _lastError = null;
    notifyListeners();
  }

  /// KaynaklarÄ± temizle (dispose Ã¶ncesi Ã§aÄŸÄ±r)
  Future<void> cleanup() async {
    _stopAiProcessing();
    await webrtc.hangUp();
    signaling.disconnect();
    await signLanguage.dispose();
    await speechToText.stopListening();
  }

  @override
  void dispose() {
    _stopAiProcessing();
    signaling.disconnect();
    // Async kaynaklar cleanup() ile Ã¶nceden temizlenmiÅŸ olmalÄ±
    // Burada sadece senkron temizlik yapÄ±lÄ±r
    super.dispose();
  }
}
