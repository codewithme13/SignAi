/// ============================================
/// SignAI - KonuÅŸmadan Metne Ã‡evirme Servisi
/// ============================================
/// YEREL mikrofonu dinleyerek bu cihazdaki
/// kullanÄ±cÄ±nÄ±n sesini yazÄ±ya Ã§evirir.
/// YazÄ±ya Ã§evrilen metin signaling Ã¼zerinden
/// karÅŸÄ± tarafa altyazÄ± olarak gÃ¶nderilir.
///
/// NOT: WebRTC remote audio stream'ini doÄŸrudan
/// STT'ye beslemek mÃ¼mkÃ¼n olmadÄ±ÄŸÄ±ndan, her iki
/// tarafta da yerel mikrofon dinlenir ve altyazÄ±
/// karÅŸÄ±lÄ±klÄ± paylaÅŸÄ±lÄ±r.
/// ============================================

import 'dart:async';
import 'package:flutter/foundation.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:speech_to_text/speech_recognition_result.dart';
import 'package:speech_to_text/speech_recognition_error.dart';

/// KonuÅŸma tanÄ±ma durumlarÄ±
enum SpeechState {
  notInitialized,
  ready,
  listening,
  paused,
  error,
}

class SpeechToTextService {
  final stt.SpeechToText _speech = stt.SpeechToText();

  // Durum
  SpeechState _state = SpeechState.notInitialized;
  bool _isInitialized = false;
  String _currentText = '';
  String _lastFinalText = '';
  String _selectedLocale = 'tr_TR'; // VarsayÄ±lan TÃ¼rkÃ§e

  // TÃ¼m konuÅŸma geÃ§miÅŸi
  final List<String> _transcriptHistory = [];

  // Callback'ler
  Function(String text, bool isFinal)? onTextRecognized;
  Function(SpeechState)? onStateChanged;
  Function(String)? onError;

  // Getter'lar
  SpeechState get state => _state;
  bool get isInitialized => _isInitialized;
  bool get isListening => _state == SpeechState.listening;
  String get currentText => _currentText;
  String get lastFinalText => _lastFinalText;
  List<String> get transcriptHistory => List.unmodifiable(_transcriptHistory);
  String get selectedLocale => _selectedLocale;

  /// Servisi baÅŸlat
  Future<bool> initialize() async {
    try {
      _isInitialized = await _speech.initialize(
        onStatus: _onStatus,
        onError: _onError,
        debugLogging: kDebugMode,
      );

      if (_isInitialized) {
        _updateState(SpeechState.ready);
        debugPrint('ğŸ™ï¸ Speech-to-Text servisi baÅŸlatÄ±ldÄ±');

        // Mevcut dilleri listele
        final locales = await _speech.locales();
        debugPrint('ğŸŒ Mevcut diller: ${locales.map((l) => l.localeId).join(', ')}');

        // TÃ¼rkÃ§e varsa seÃ§
        final turkishLocale = locales.firstWhere(
          (l) => l.localeId.startsWith('tr'),
          orElse: () => locales.first,
        );
        _selectedLocale = turkishLocale.localeId;
        debugPrint('ğŸŒ SeÃ§ilen dil: $_selectedLocale');
      } else {
        _updateState(SpeechState.error);
        debugPrint('âŒ Speech-to-Text baÅŸlatÄ±lamadÄ±');
      }

      return _isInitialized;
    } catch (e) {
      debugPrint('âŒ Speech-to-Text baÅŸlatma hatasÄ±: $e');
      _updateState(SpeechState.error);
      return false;
    }
  }

  /// Dinlemeye baÅŸla
  Future<void> startListening() async {
    if (!_isInitialized) {
      debugPrint('âš ï¸ Speech servisi baÅŸlatÄ±lmamÄ±ÅŸ');
      return;
    }

    if (_state == SpeechState.listening) {
      debugPrint('âš ï¸ Zaten dinleniyor');
      return;
    }

    try {
      await _speech.listen(
        onResult: _onResult,
        localeId: _selectedLocale,
        listenMode: stt.ListenMode.dictation, // SÃ¼rekli dinleme modu
        cancelOnError: false,
        partialResults: true,
        listenFor: const Duration(seconds: 30), // 30 saniye dinle, sonra yeniden baÅŸla
      );

      _updateState(SpeechState.listening);
      debugPrint('ğŸ™ï¸ Dinleme baÅŸladÄ±');
    } catch (e) {
      debugPrint('âŒ Dinleme baÅŸlatma hatasÄ±: $e');
      _updateState(SpeechState.error);
    }
  }

  /// Dinlemeyi durdur
  Future<void> stopListening() async {
    if (_state != SpeechState.listening) return;

    try {
      await _speech.stop();
      _updateState(SpeechState.ready);
      debugPrint('ğŸ™ï¸ Dinleme durduruldu');
    } catch (e) {
      debugPrint('âŒ Dinleme durdurma hatasÄ±: $e');
    }
  }

  /// Dinlemeyi aÃ§/kapa
  Future<void> toggleListening() async {
    if (_state == SpeechState.listening) {
      await stopListening();
    } else {
      await startListening();
    }
  }

  /// Dili deÄŸiÅŸtir
  void setLocale(String localeId) {
    _selectedLocale = localeId;
    debugPrint('ğŸŒ Dil deÄŸiÅŸtirildi: $localeId');

    // EÄŸer dinliyorsa, yeniden baÅŸlat
    if (_state == SpeechState.listening) {
      stopListening().then((_) => startListening());
    }
  }

  /// Mevcut dilleri getir
  Future<List<stt.LocaleName>> getLocales() async {
    if (!_isInitialized) return [];
    return _speech.locales();
  }

  /// KonuÅŸma tanÄ±ma sonucu
  void _onResult(SpeechRecognitionResult result) {
    _currentText = result.recognizedWords;

    if (result.finalResult) {
      // KesinleÅŸmiÅŸ sonuÃ§
      _lastFinalText = _currentText;
      if (_currentText.isNotEmpty) {
        _transcriptHistory.add(_currentText);
      }
      onTextRecognized?.call(_currentText, true);
      debugPrint('ğŸ“ Kesin metin: $_currentText');

      // Otomatik yeniden dinlemeye baÅŸla
      _autoRestart();
    } else {
      // GeÃ§ici sonuÃ§ (henÃ¼z konuÅŸma devam ediyor)
      onTextRecognized?.call(_currentText, false);
    }
  }

  /// Dinleme otomatik yeniden baÅŸlatma
  int _restartCount = 0;
  static const int _maxAutoRestarts = 100; // Sonsuz dÃ¶ngÃ¼yÃ¼ engelle

  Future<void> _autoRestart() async {
    if (_restartCount >= _maxAutoRestarts) {
      debugPrint('âš ï¸ Maksimum otomatik yeniden baÅŸlatma sayÄ±sÄ±na ulaÅŸÄ±ldÄ±');
      _restartCount = 0;
      return;
    }

    // KÄ±sa bir bekleme sonrasÄ± yeniden baÅŸla
    await Future.delayed(const Duration(milliseconds: 500));
    if (_state == SpeechState.listening || _state == SpeechState.ready) {
      _restartCount++;
      await startListening();
    }
  }

  /// Durum deÄŸiÅŸikliÄŸi
  void _onStatus(String status) {
    debugPrint('ğŸ™ï¸ Speech durumu: $status');

    switch (status) {
      case 'listening':
        _updateState(SpeechState.listening);
        break;
      case 'notListening':
        if (_state != SpeechState.error) {
          _updateState(SpeechState.ready);
        }
        break;
      case 'done':
        _updateState(SpeechState.ready);
        break;
    }
  }

  /// Hata
  void _onError(SpeechRecognitionError error) {
    debugPrint('âŒ Speech hatasÄ±: ${error.errorMsg} (${error.permanent})');

    if (error.permanent) {
      _updateState(SpeechState.error);
    }

    onError?.call(error.errorMsg);
  }

  /// Durumu gÃ¼ncelle
  void _updateState(SpeechState newState) {
    _state = newState;
    onStateChanged?.call(newState);
  }

  /// GeÃ§miÅŸi temizle
  void clearHistory() {
    _transcriptHistory.clear();
    _currentText = '';
    _lastFinalText = '';
  }

  /// TÃ¼m geÃ§miÅŸi birleÅŸtir
  String getFullTranscript() {
    return _transcriptHistory.join('. ');
  }

  /// Servisi kapat
  Future<void> dispose() async {
    await _speech.stop();
    await _speech.cancel();
    _isInitialized = false;
    _updateState(SpeechState.notInitialized);
    debugPrint('ğŸ™ï¸ Speech-to-Text servisi kapatÄ±ldÄ±');
  }
}
